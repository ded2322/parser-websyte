# **Документация к парсеру**

## **2. Используемые технологии**

- **Python 3.11**

- **Selenium** Для выполнения запросов к сайту

## **3. Как пользоваться**

### **3.1 Установка**
1. **Клонирование репозитория**  
    ```bash
    git clone https://github.com/ded2322/parser-websyte.git
    ```
2. **Создание и активация виртуальной среды** (если используется Python)  
    ```bash
    python -m venv venv
    source venv/bin/activate  # Для Linux/MacOS
    venv\Scripts\activate  # Для Windows
    ```
3. **Установка зависимостей**  
    ```bash
    pip install -r requirements.txt
    ```

### **3.2 Запуск парсера**
1. **Конфигурация**  
   В .env файл находится переменная BASE_URL с ссылкой на сайт
2. Должен быть установлен firefox или в модуле utils изменен движок
3. **Запуск**  
   Запустите парсер с помощью следующей команды:
   ```bash
   python main.py
   ```


## **4. Просмотр результата**

### **4.1 Формат вывода**
Результаты парсинга сохраняются в формате CSV. 


### **4.2 Просмотр данных**

Если данные отображаются не совсем корректно.
То нужно:
Открыть exel -> выбрать "Данные" -> 
"Из текста/CSV" -> Найти и выбрать нужный файл 
-> Источник файла -> Юнит-код


## **5. Недоработанные или незавершенные функции**
Многопоточность, переход в разные формы товаров, разные тт.
Ну собственно говоря что вы хотели за 8 часов от человека который до этого 1 раз парсер писал.
